<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Projects - Nomesh Palakaluri</title>
    <link rel="stylesheet" href="styles.css">
</head>
<body>
    <header class="header">
        <h1>Projects</h1>
    </header>
    <nav class="navbar">
        <ul>
            <li><a href="index.html">Home</a></li>
            <li><a href="about.html">About Me</a></li>
            <li><a href="skills.html">Skills</a></li>
            <li><a href="contact.html">Contact</a></li>
        </ul>
    </nav>
    <section class="section">
        <h2>Real-Time Data Ingestion and Processing</h2>
        <h3>Project Overview</h3>
        <p>
            Developed a real-time data ingestion pipeline to process and analyze customer interaction data from web applications, mobile apps, and IoT devices. The system was designed to handle high throughput and deliver actionable insights in near real-time.
        </p>
        <h3>Tech Stack</h3>
        <p>
            <strong>Data Sources:</strong> Clickstreams, IoT sensors, mobile app events.<br>
            <strong>Tools:</strong> <strong>Apache Kafka, Apache Flink, AWS Lambda, Amazon S3, Elasticsearch</strong>.<br>
            <strong>Storage:</strong> <strong>Amazon S3</strong> for raw and processed data, <strong>Elasticsearch</strong> for analytics.
        </p>
        <h3>Work Done</h3>
        <ul>
            <li>Integrated clickstream, IoT events, and mobile logs into <strong>Apache Kafka</strong> for real-time ingestion.</li>
            <li>Stored raw data in <strong>Amazon S3</strong> and processed data in <strong>Elasticsearch</strong> for real-time dashboards.</li>
            <li>Implemented tiered storage in <strong>Amazon S3</strong>, reducing storage costs by <strong>40%</strong>.</li>
            <li>Processed <strong>500GB/day</strong> of data with low-latency processing using <strong>Apache Flink</strong>.</li>
            <li>Achieved <strong>99.9%</strong> event delivery reliability with a message processing latency under <strong>500ms</strong>.</li>
        </ul>
        <h3>Outcome</h3>
        <p>
            Enabled real-time monitoring of customer interaction metrics such as session duration, click paths, and engagement rates.
        </p>
        <h3>Impact</h3>
        <p>
            Reduced marketing feedback loop from <strong>hours to minutes</strong>, increasing user engagement by <strong>15%</strong>.
        </p>

        <h2>Data Migration</h2>
        <h3>Project Overview</h3>
        <p>
            Migrated 3TB of on-premises transactional and analytical data from SQL Server to AWS Redshift, ensuring scalability, performance optimization, and cost efficiency.
        </p>
        <h3>Tech Stack</h3>
        <p>
            <strong>Data Sources:</strong> On-premises SQL Server and Oracle databases.<br>
            <strong>Tools:</strong> <strong>AWS DMS, AWS Glue, AWS Redshift, Amazon S3</strong>.<br>
            <strong>Storage:</strong> <strong>AWS Redshift</strong> for analytics, <strong>Amazon S3</strong> for raw backups.
        </p>
        <h3>Work Done</h3>
        <ul>
            <li>Set up full and incremental data replication using <strong>AWS DMS</strong>.</li>
            <li>Migrated data to <strong>AWS Redshift</strong> and stored backups in <strong>Amazon S3</strong>.</li>
            <li>Optimized Redshift queries with SORT and DIST keys, improving query runtime by <strong>40%</strong>.</li>
            <li>Processed an average of <strong>500GB/day</strong> with CDC for real-time updates.</li>
            <li>Achieved <strong>99.9%</strong> data integrity during migration.</li>
        </ul>
        <h3>Outcome</h3>
        <p>
            Delivered a high-performing analytics environment with minimal downtime during migration.
        </p>
        <h3>Impact</h3>
        <p>
            Reduced infrastructure costs by <strong>50%</strong> and improved query performance, enabling faster decision-making.
        </p>

        <h2>Data Engineering Workflow Automation</h2>
        <h3>Project Overview</h3>
        <p>
            Built an automated data integration platform to consolidate data from CRM, ERP, and third-party systems into a centralized data warehouse for business intelligence and reporting.
        </p>
        <h3>Tech Stack</h3>
        <p>
            <strong>Data Sources:</strong> Salesforce, SAP, Google Analytics.<br>
            <strong>Tools:</strong> <strong>Azure Data Factory, Azure Synapse Analytics, Power BI, Python</strong>.<br>
            <strong>Storage:</strong> <strong>Azure Data Lake</strong> for raw data, <strong>Azure Synapse</strong> for structured analytics.
        </p>
        <h3>Work Done</h3>
        <ul>
            <li>Extracted data from <strong>Salesforce</strong>, <strong>SAP</strong>, and <strong>Google Analytics</strong> using <strong>ADF</strong> pipelines.</li>
            <li>Designed a star schema in <strong>Azure Synapse Analytics</strong>, optimizing data models for analytics.</li>
            <li>Implemented partitioned tables and columnstore indexing, reducing storage costs by <strong>30%</strong>.</li>
            <li>Processed <strong>1TB/day</strong> of data across the integration pipeline.</li>
            <li>Reduced ETL pipeline runtime by <strong>40%</strong> through optimized workflows.</li>
        </ul>
        <h3>Outcome</h3>
        <p>
            Delivered robust and automated data pipelines with error handling and retry mechanisms.
        </p>
        <h3>Impact</h3>
        <p>
            Saved over <strong>20 hours/week</strong> of manual effort and provided near-real-time insights to stakeholders.
        </p>
    </section>
    <footer class="footer">
        <p>&copy; 2025 Nomesh Palakaluri. All rights reserved.</p>
    </footer>
</body>
</html>
