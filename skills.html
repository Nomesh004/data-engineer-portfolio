<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Skills - Nomesh Palakaluri</title>
    <link rel="stylesheet" href="styles.css">
</head>
<body>
    <header class="header">
        <h1>Skills</h1>
    </header>
    <nav class="navbar">
        <ul>
            <li><a href="index.html">Home</a></li>
            <li><a href="about.html">About Me</a></li>
            <li><a href="projects.html">Projects</a></li>
            <li><a href="contact.html">Contact</a></li>
        </ul>
    </nav>
    <section class="section">
        <h2>Programming Languages</h2>
        <ul>
            <li><strong>Python:</strong> Built ETL pipelines and implemented data transformations for financial platforms using <strong>Python</strong> scripts.</li>
            <li><strong>SQL:</strong> Optimized complex <strong>SQL</strong> queries to enhance the performance of analytics dashboards and reporting.</li>
            <li><strong>PL/SQL:</strong> Created stored procedures and triggers to manage transactional workflows in <strong>PL/SQL</strong> databases.</li>
            <li><strong>Scala:</strong> Utilized <strong>Scala</strong> with Apache Spark for distributed data processing and large-scale analytics.</li>
            <li><strong>R:</strong> Conducted statistical analysis and visualization for business insights in exploratory data analysis using <strong>R</strong>.</li>
            <li><strong>Java:</strong> Developed backend logic for real-time data ingestion pipelines using <strong>Java</strong>.</li>
            <li><strong>JavaScript, HTML, CSS:</strong> Built interactive dashboards and web-based interfaces for data visualization projects using <strong>JavaScript, HTML, and CSS</strong>.</li>
        </ul>

        <h2>Python Libraries</h2>
        <ul>
            <li><strong>NumPy & Pandas:</strong> Performed data cleansing and transformation in <strong>NumPy</strong> and <strong>Pandas</strong>-based analytics workflows.</li>
            <li><strong>TensorFlow:</strong> Experimented with <strong>TensorFlow</strong> to implement machine learning models for predictive analytics and data forecasting.</li>
        </ul>

        <h2>Azure Tools</h2>
        <ul>
            <li><strong>Data Factory:</strong> Automated ETL processes using <strong>Azure Data Factory</strong> to ingest data into Azure Synapse Analytics.</li>
            <li><strong>Databricks:</strong> Utilized <strong>Azure Databricks</strong> for batch and real-time big data processing with PySpark.</li>
            <li><strong>DevOps:</strong> Deployed CI/CD pipelines for data workflows using <strong>Azure DevOps</strong>.</li>
            <li><strong>Functions:</strong> Created event-driven workflows with <strong>Azure Functions</strong> to automate notifications.</li>
            <li><strong>Synapse:</strong> Designed and maintained a data warehouse on <strong>Azure Synapse</strong> to support scalable analytics.</li>
            <li><strong>Data Lake:</strong> Implemented <strong>Azure Data Lake</strong> for efficient big data storage and processing.</li>
            <li><strong>Blob Storage:</strong> Used <strong>Azure Blob Storage</strong> for archiving large datasets and backups.</li>
        </ul>

        <h2>AWS Tools</h2>
        <ul>
            <li><strong>S3:</strong> Stored and retrieved data for analytics workflows using <strong>AWS S3</strong>.</li>
            <li><strong>Redshift:</strong> Designed a centralized data warehouse on <strong>AWS Redshift</strong> for business intelligence reporting.</li>
            <li><strong>Glue:</strong> Automated data ingestion pipelines with <strong>AWS Glue</strong> for processing multi-source data.</li>
            <li><strong>Lambda:</strong> Built serverless functions with <strong>AWS Lambda</strong> to handle event-driven tasks.</li>
            <li><strong>EMR:</strong> Processed large-scale data using <strong>AWS EMR</strong> clusters with Apache Spark.</li>
            <li><strong>Athena:</strong> Queried data stored in S3 using <strong>AWS Athena</strong> for ad hoc analysis.</li>
            <li><strong>Kinesis:</strong> Implemented <strong>AWS Kinesis</strong> to manage real-time streaming data pipelines.</li>
            <li><strong>RDS & Aurora:</strong> Managed transactional databases on <strong>AWS RDS</strong> and <strong>Aurora</strong>.</li>
        </ul>

        <h2>CI/CD Tools</h2>
        <ul>
            <li><strong>Docker:</strong> Containerized data engineering applications using <strong>Docker</strong> for seamless deployments.</li>
            <li><strong>Terraform:</strong> Automated infrastructure provisioning using <strong>Terraform</strong> for cloud environments.</li>
            <li><strong>Kubernetes:</strong> Deployed scalable workloads using <strong>Kubernetes</strong> for big data processing.</li>
            <li><strong>Git & GitHub:</strong> Managed version control and collaboration for projects using <strong>Git</strong> and <strong>GitHub</strong>.</li>
            <li><strong>Jenkins:</strong> Set up CI/CD pipelines using <strong>Jenkins</strong> for automated builds and deployments.</li>
        </ul>

        <h2>Database Systems</h2>
        <ul>
            <li><strong>MySQL:</strong> Designed and optimized relational database schemas using <strong>MySQL</strong>.</li>
            <li><strong>PostgreSQL:</strong> Managed large datasets and complex queries in <strong>PostgreSQL</strong> for analytics workflows.</li>
            <li><strong>MongoDB:</strong> Built NoSQL solutions using <strong>MongoDB</strong> for unstructured data storage.</li>
            <li><strong>Snowflake:</strong> Migrated large datasets to <strong>Snowflake</strong> to enable faster query performance.</li>
        </ul>

        <h2>Big Data Tools</h2>
        <ul>
            <li><strong>Apache Spark:</strong> Processed large datasets for analytics workflows using <strong>Apache Spark</strong> with Scala and PySpark.</li>
            <li><strong>Apache Kafka:</strong> Built real-time data ingestion pipelines using <strong>Apache Kafka</strong> for seamless processing.</li>
            <li><strong>Hadoop:</strong> Implemented <strong>Hadoop</strong> for distributed storage and computation of big data.</li>
            <li><strong>Airflow:</strong> Orchestrated data workflows using <strong>Apache Airflow</strong> to automate pipeline execution.</li>
        </ul>

        <h2>Visualization Tools</h2>
        <ul>
            <li><strong>Tableau:</strong> Developed dynamic dashboards in <strong>Tableau</strong> for insightful reporting.</li>
            <li><strong>Power BI:</strong> Created interactive business intelligence reports using <strong>Power BI</strong>.</li>
            <li><strong>Looker:</strong> Designed analytics views and models in <strong>Looker</strong> for data-driven insights.</li>
            <li><strong>SSRS:</strong> Built paginated reports in <strong>SSRS</strong> for operational data needs.</li>
        </ul>
    </section>
    <footer class="footer">
        <p>&copy; 2025 Nomesh Palakaluri. All rights reserved.</p>
    </footer>
</body>
</html>
